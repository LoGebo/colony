---
phase: 08-governance-analytics
plan: 08
type: execute
wave: 2
depends_on: ["08-01", "08-04", "08-07"]
files_modified:
  - supabase/migrations/TIMESTAMP_kpi_tables.sql
  - supabase/migrations/TIMESTAMP_kpi_functions.sql
  - supabase/migrations/TIMESTAMP_kpi_cron_jobs.sql
autonomous: true

must_haves:
  truths:
    - "Daily KPIs aggregate access, incidents, payments, packages metrics"
    - "Weekly KPIs aggregate daily data with trend calculations"
    - "Monthly KPIs include financial summaries and delinquency tracking"
    - "Summary tables are refreshed via pg_cron (not materialized views)"
    - "KPIs are queryable by date range for dashboards"
  artifacts:
    - path: "supabase/migrations/*_kpi_tables.sql"
      provides: "kpi_daily, kpi_weekly, kpi_monthly summary tables"
    - path: "supabase/migrations/*_kpi_functions.sql"
      provides: "compute_daily_kpis(), compute_weekly_kpis(), compute_monthly_kpis() functions"
    - path: "supabase/migrations/*_kpi_cron_jobs.sql"
      provides: "pg_cron scheduled jobs for KPI refresh"
  key_links:
    - from: "compute_daily_kpis()"
      to: "access_logs, incidents, transactions, packages, tickets"
      via: "aggregates metrics from operational tables"
    - from: "pg_cron jobs"
      to: "compute_*_kpis functions"
      via: "scheduled refresh"
    - from: "kpi_weekly/monthly"
      to: "kpi_daily"
      via: "aggregates daily data"
---

<objective>
Create the pre-computed analytics schema with summary tables for daily, weekly, and monthly KPIs refreshed via pg_cron jobs.

Purpose: Enable fast dashboard queries by pre-computing metrics instead of real-time aggregation. Uses summary tables (not materialized views) for PowerSync compatibility.

Output: KPI tables, computation functions, and pg_cron scheduled refresh jobs.
</objective>

<execution_context>
@.claude/get-shit-done/workflows/execute-plan.md
@.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-governance-analytics/08-RESEARCH.md

# Prior infrastructure (KPIs depend on data from these)
@.planning/phases/03-access-control-security/03-02-SUMMARY.md (access_logs)
@.planning/phases/04-financial-engine/04-02-SUMMARY.md (transactions)
@.planning/phases/06-maintenance-chat-documents-notifications/06-01-SUMMARY.md (tickets)
@.planning/phases/07-operations-compliance/07-01-SUMMARY.md (packages)
@.planning/phases/08-governance-analytics/08-01-SUMMARY.md (incidents)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create KPI summary tables</name>
  <files>supabase/migrations/TIMESTAMP_kpi_tables.sql</files>
  <action>
Create migration with KPI summary tables:

**Note:** Using summary tables instead of materialized views for PowerSync compatibility. Summary tables allow incremental updates and work with offline-sync architecture.

**kpi_daily table:**
- id UUID PK DEFAULT generate_uuid_v7()
- community_id UUID NOT NULL REFERENCES communities(id)
- metric_date DATE NOT NULL
- Access metrics: total_entries INTEGER DEFAULT 0, resident_entries INTEGER DEFAULT 0, visitor_entries INTEGER DEFAULT 0, denied_entries INTEGER DEFAULT 0
- Peak hours: entries_by_hour JSONB DEFAULT '{}' -- {"08": 45, "09": 67, ...}
- Security: incidents_reported INTEGER DEFAULT 0, incidents_resolved INTEGER DEFAULT 0, patrol_checkpoints_completed INTEGER DEFAULT 0, patrol_checkpoints_missed INTEGER DEFAULT 0
- Financial: payments_received INTEGER DEFAULT 0, payments_amount money_amount DEFAULT 0, new_charges_count INTEGER DEFAULT 0, new_charges_amount money_amount DEFAULT 0
- Delinquency: units_delinquent INTEGER DEFAULT 0, total_delinquent_amount money_amount DEFAULT 0
- Communication: announcements_sent INTEGER DEFAULT 0, messages_sent INTEGER DEFAULT 0
- Amenities: reservations_made INTEGER DEFAULT 0, reservations_cancelled INTEGER DEFAULT 0, no_shows INTEGER DEFAULT 0
- Packages: packages_received INTEGER DEFAULT 0, packages_picked_up INTEGER DEFAULT 0, packages_pending INTEGER DEFAULT 0
- Maintenance: tickets_opened INTEGER DEFAULT 0, tickets_closed INTEGER DEFAULT 0
- computed_at TIMESTAMPTZ NOT NULL DEFAULT now()
- UNIQUE (community_id, metric_date)

**kpi_weekly table:**
- id UUID PK DEFAULT generate_uuid_v7()
- community_id UUID NOT NULL REFERENCES communities(id)
- week_start DATE NOT NULL -- Monday of the week
- week_number INTEGER NOT NULL
- year INTEGER NOT NULL
- Aggregated metrics: total_entries INTEGER, incidents_reported INTEGER, incidents_resolved INTEGER, payments_amount money_amount, avg_daily_entries NUMERIC(10,2)
- Trends: entries_change_pct NUMERIC(5,2), incidents_change_pct NUMERIC(5,2) -- vs previous week
- computed_at TIMESTAMPTZ NOT NULL DEFAULT now()
- UNIQUE (community_id, year, week_number)

**kpi_monthly table:**
- id UUID PK DEFAULT generate_uuid_v7()
- community_id UUID NOT NULL REFERENCES communities(id)
- month INTEGER NOT NULL
- year INTEGER NOT NULL
- Financial: total_billed money_amount DEFAULT 0, total_collected money_amount DEFAULT 0, collection_rate NUMERIC(5,2) DEFAULT 0
- Delinquency: units_delinquent_30_days INTEGER DEFAULT 0, units_delinquent_60_days INTEGER DEFAULT 0, units_delinquent_90_days INTEGER DEFAULT 0
- Access: total_entries INTEGER DEFAULT 0, unique_visitors INTEGER DEFAULT 0
- Security: total_incidents INTEGER DEFAULT 0, incidents_by_category JSONB DEFAULT '{}', avg_resolution_hours NUMERIC(10,2)
- Amenities: total_reservations INTEGER DEFAULT 0, utilization_by_amenity JSONB DEFAULT '{}'
- Trends: collection_rate_change NUMERIC(5,2) -- vs previous month
- computed_at TIMESTAMPTZ NOT NULL DEFAULT now()
- UNIQUE (community_id, year, month)

**Indexes:**
BRIN indexes for time-series queries (efficient for append-only data):
- CREATE INDEX idx_kpi_daily_date_brin ON kpi_daily USING BRIN (metric_date)
- CREATE INDEX idx_kpi_weekly_week_brin ON kpi_weekly USING BRIN (week_start)
- CREATE INDEX idx_kpi_monthly_period_brin ON kpi_monthly USING BRIN (year, month)

B-tree for community filtering:
- CREATE INDEX idx_kpi_daily_community ON kpi_daily (community_id, metric_date DESC)
- CREATE INDEX idx_kpi_weekly_community ON kpi_weekly (community_id, year DESC, week_number DESC)
- CREATE INDEX idx_kpi_monthly_community ON kpi_monthly (community_id, year DESC, month DESC)

RLS policies:
- Community admins can SELECT their community's KPIs
- Platform admins can SELECT all
  </action>
  <verify>Run migration. Verify tables created with BRIN indexes.</verify>
  <done>KPI summary tables with optimized indexes for time-series queries</done>
</task>

<task type="auto">
  <name>Task 2: Create KPI computation functions</name>
  <files>supabase/migrations/TIMESTAMP_kpi_functions.sql</files>
  <action>
Create migration with KPI computation functions:

**compute_daily_kpis(p_community_id UUID, p_date DATE) function:**
- Aggregates metrics from operational tables for a specific date
- Uses UPSERT (ON CONFLICT ... DO UPDATE) for idempotent execution
- Queries:
  - access_logs: COUNT by entry_type, denied status, EXTRACT hour for hourly breakdown
  - incidents: COUNT by reported_at::DATE, resolved_at::DATE
  - patrol_logs: COUNT checkpoints
  - transactions: COUNT/SUM for payments and charges by posted_at::DATE
  - unit_balances: COUNT/SUM delinquent amounts
  - announcements: COUNT by created_at::DATE
  - messages: COUNT by created_at::DATE
  - reservations: COUNT by created_at::DATE, status
  - packages: COUNT by received_at, picked_up_at
  - tickets: COUNT by created_at, resolved_at

**compute_weekly_kpis(p_community_id UUID, p_week_start DATE) function:**
- Aggregates from kpi_daily for the week (7 days starting from week_start)
- Calculates averages (avg_daily_entries)
- Calculates trends vs previous week:
  - previous_total = SUM from kpi_daily WHERE metric_date BETWEEN week_start - 14 AND week_start - 8
  - current_total = SUM from kpi_daily WHERE metric_date BETWEEN week_start AND week_start + 6
  - change_pct = ((current - previous) / NULLIF(previous, 0)) * 100

**compute_monthly_kpis(p_community_id UUID, p_year INTEGER, p_month INTEGER) function:**
- Aggregates from kpi_daily for the month
- Calculates financial metrics:
  - total_billed from fee_schedules/transactions
  - collection_rate = (total_collected / NULLIF(total_billed, 0)) * 100
- Calculates delinquency buckets (30/60/90 days) from unit_balances
- Calculates avg_resolution_hours from incidents
- Aggregates by category for incidents_by_category, utilization_by_amenity

**compute_all_daily_kpis(p_date DATE) function:**
- Iterates all active communities
- Calls compute_daily_kpis for each

**compute_all_weekly_kpis(p_week_start DATE) function:**
- Same pattern for weekly

**compute_all_monthly_kpis(p_year INTEGER, p_month INTEGER) function:**
- Same pattern for monthly

**backfill_kpis(p_community_id UUID, p_start_date DATE, p_end_date DATE) function:**
- Backfills daily KPIs for historical data
- Useful for new communities or data corrections
- Loops through date range calling compute_daily_kpis
  </action>
  <verify>
Test computation:
1. Insert test data in operational tables
2. Call compute_daily_kpis - verify row created
3. Call again - verify UPSERT updates (no duplicate)
4. Call compute_weekly_kpis - verify aggregation correct
5. Call compute_monthly_kpis - verify financial calculations
  </verify>
  <done>KPI computation functions with trend calculations and backfill support</done>
</task>

<task type="auto">
  <name>Task 3: Create pg_cron scheduled jobs for KPI refresh</name>
  <files>supabase/migrations/TIMESTAMP_kpi_cron_jobs.sql</files>
  <action>
Create migration with pg_cron scheduled jobs:

**Enable pg_cron extension (if not already):**
```sql
CREATE EXTENSION IF NOT EXISTS pg_cron WITH SCHEMA extensions;
```

**Daily KPI computation job:**
- Schedule: '0 1 * * *' (1:00 AM daily)
- Computes previous day's KPIs for all communities
```sql
SELECT cron.schedule(
  'compute-daily-kpis',
  '0 1 * * *',
  $$SELECT compute_all_daily_kpis(CURRENT_DATE - 1)$$
);
```

**Weekly KPI aggregation job:**
- Schedule: '0 2 * * 1' (2:00 AM on Mondays)
- Computes previous week's aggregated KPIs
```sql
SELECT cron.schedule(
  'compute-weekly-kpis',
  '0 2 * * 1',
  $$SELECT compute_all_weekly_kpis(date_trunc('week', CURRENT_DATE - 7)::DATE)$$
);
```

**Monthly KPI aggregation job:**
- Schedule: '0 3 1 * *' (3:00 AM on 1st of each month)
- Computes previous month's aggregated KPIs
```sql
SELECT cron.schedule(
  'compute-monthly-kpis',
  '0 3 1 * *',
  $$SELECT compute_all_monthly_kpis(
    EXTRACT(YEAR FROM CURRENT_DATE - INTERVAL '1 month')::INTEGER,
    EXTRACT(MONTH FROM CURRENT_DATE - INTERVAL '1 month')::INTEGER
  )$$
);
```

**Create view for cron job status monitoring:**
```sql
CREATE VIEW cron_job_status AS
SELECT
  jobid,
  jobname,
  schedule,
  (SELECT MAX(start_time) FROM cron.job_run_details WHERE jobid = cron.job.jobid) AS last_run,
  (SELECT status FROM cron.job_run_details WHERE jobid = cron.job.jobid ORDER BY start_time DESC LIMIT 1) AS last_status
FROM cron.job;
```

**Helper function to manually trigger KPI refresh:**
```sql
CREATE OR REPLACE FUNCTION refresh_kpis(
  p_community_id UUID,
  p_days_back INTEGER DEFAULT 7
) RETURNS VOID
LANGUAGE plpgsql
AS $$
DECLARE
  v_date DATE;
BEGIN
  FOR v_date IN
    SELECT generate_series(
      CURRENT_DATE - p_days_back,
      CURRENT_DATE - 1,
      '1 day'::INTERVAL
    )::DATE
  LOOP
    PERFORM compute_daily_kpis(p_community_id, v_date);
  END LOOP;
END;
$$;
```
  </action>
  <verify>
Verify cron jobs:
1. Check cron jobs scheduled: SELECT * FROM cron.job;
2. Run manual KPI computation
3. Verify cron_job_status view works
4. Test refresh_kpis helper function
  </verify>
  <done>pg_cron scheduled jobs for automated KPI refresh</done>
</task>

</tasks>

<verification>
-- Verify KPI tables exist
\d kpi_daily
\d kpi_weekly
\d kpi_monthly

-- Check BRIN indexes
SELECT indexname, indexdef FROM pg_indexes WHERE tablename LIKE 'kpi_%';

-- Test daily KPI computation
SELECT compute_daily_kpis('community-id', CURRENT_DATE - 1);
SELECT * FROM kpi_daily WHERE community_id = 'community-id' ORDER BY metric_date DESC LIMIT 1;

-- Test idempotent UPSERT (run again, should update not duplicate)
SELECT compute_daily_kpis('community-id', CURRENT_DATE - 1);
SELECT COUNT(*) FROM kpi_daily WHERE community_id = 'community-id' AND metric_date = CURRENT_DATE - 1;
-- Should return 1

-- Verify cron jobs scheduled
SELECT jobname, schedule FROM cron.job WHERE jobname LIKE 'compute-%';
-- Should show:
--   compute-daily-kpis    | 0 1 * * *
--   compute-weekly-kpis   | 0 2 * * 1
--   compute-monthly-kpis  | 0 3 1 * *

-- Test manual refresh
SELECT refresh_kpis('community-id', 7);
SELECT COUNT(*) FROM kpi_daily WHERE community_id = 'community-id' AND metric_date >= CURRENT_DATE - 7;
-- Should return 7

-- Query dashboard data
SELECT metric_date, total_entries, incidents_reported, payments_amount
FROM kpi_daily
WHERE community_id = 'community-id'
AND metric_date >= CURRENT_DATE - 30
ORDER BY metric_date DESC;
</verification>

<success_criteria>
- kpi_daily captures all operational metrics
- kpi_weekly aggregates with trend calculations (% change)
- kpi_monthly includes financial summaries and delinquency buckets
- BRIN indexes optimize time-series queries
- compute_daily_kpis aggregates from all operational tables
- UPSERT pattern makes computation idempotent
- compute_weekly/monthly aggregate from daily data
- pg_cron jobs scheduled at appropriate times (1am daily, 2am Monday, 3am 1st)
- backfill_kpis supports historical data population
- refresh_kpis provides manual trigger for admins
- Summary tables work with PowerSync (not materialized views)
</success_criteria>

<output>
After completion, create `.planning/phases/08-governance-analytics/08-08-SUMMARY.md`
</output>
